<!DOCTYPE html>
<html>
   <head>
   <style type="text/css" media="all">

	body{background: #466368;
		background: -webkit-linear-gradient(#999999, #990000);
		background:    -moz-linear-gradient(#999999, #990000);
		background:         linear-gradient(#999999, #990000);}
	img{}
	h2{ color:white; font-size:30px; text-align:center;}
	ol{ color:white; font-family:Times New Roman; font-style:normal; font-size:20pt; }
	table{ color:white; font-family:Arial; font-style:normal; font-size:13pt }
	p{ color:white; text-align:left;}
	a{color:white;}
	
	
	</style>
      <title>    Intro to Parallel Programming       </title>
   </head>
   <body><meta name = "keywords" content = "computer, science, intro, 100, CSC, HTML">
   			<div id="image" style="display:inline;">
			<center><img style="height:147px; width:486px" src="StMartinlogoTP.png"/>
			</div>
			
			<h2>  Welcome to Parallel Programming Class! </h2>
			<h2>  Chapter 8 - OpenMP Directives and Other Function Calls </h2></font>
			<center><p>
Synchronization Constructs
<p>Consider a simple example where two threads are both trying to update variable x at the same time: 
 
<p>One possible execution sequence: 
<p>Thread 1 initializes x to 0 and calls update(x) 
<p>Thread 1 adds 1 to x. 
<p>x now equals 1 
<p>Thread 2 initializes x to 0 and calls update(x) 
<p>x now equals 0 
<p>Thread 1 prints x, which is equal to 0 instead of 1 
<p>Thread 2 adds 1 to x. 
<p>x now equals 1. 
<p>Thread 2 prints x as 1. 

<p>To avoid a situation like this, the updating of x must be synchronized between the two threads to ensure that the correct result is produced. 
OpenMP provides a variety of Synchronization Constructs that control how the execution of each thread proceeds relative to other team threads.

<p>The MASTER directive specifies a region that is to be executed only by the master thread of the team. All other threads on the team skip this section of code.
There is no implied barrier associated with this directive. This is the format for the MASTER directive in C/C++:

<p>#pragma omp master  newline

   structured_block

<p>The CRITICAL directive specifies a region of code that must be executed by only one thread at a time. If a thread is currently executing inside a CRITICAL region and another thread reaches that CRITICAL region and attempts to execute it, it will block until the first thread exits that CRITICAL region.
This is the format for the CRITICAL directive in C/C++:
<p>#pragma omp critical [ name ]  newline

   structured_block

<p>The BARRIER directive synchronizes all threads in the team. 
When a BARRIER directive is reached, a thread will wait at that point until all other threads have reached that barrier. All threads then resume executing in parallel the code that follows the barrier.
This is the format for the BARRIER directive in C/C++:
<p>#pragma omp barrier  newline

<p>The ORDERED directive specifies that iterations of the enclosed loop will be executed in the same order as if they were executed on a serial processor. 
Threads will need to wait before executing their chunk of iterations if previous iterations haven't completed yet. 
Used within a DO / for loop with an ORDERED clause 
The ORDERED directive provides a way to "fine tune" where ordering is to be applied within a loop. Otherwise, it is not required.
This is the format for the ORDERED directive in C/C++:
<p>#pragma omp for ordered [clauses...]
   (loop region)
<p>#pragma omp ordered  newline
  structured_block
   (endo of loop region)

<p>Run-Time Library Routines
<p>The OpenMP API includes an ever-growing number of run-time library routines. 
<p>These routines are used for a variety of purposes as shown in the table below:
 

<p>The following are a few important Run-Time Library Routines and a more in-depth explanationâ€¦

<p>omp_set_num_threads()
<p>Sets the number of threads that will be used in the next parallel region. Must be a postive integer.
<p>Format(C/C++): 
<p>#include <omp.h>
<p>void omp_set_num_threads(int num_threads)

<p>omp_get_num_threads()
<p>Returns the number of threads that are currently in the team executing the parallel region from which it is called.
<p>Format(C/C++): 
<p>#include <omp.h>
<p>int omp_get_num_threads(void)

<p>omp_get_max_threads()
<p>Returns the maximum value that can be returned by a call to the OMP_GET_NUM_THREADS function.
<p>Format(C/C++):
<p>#include <omp.h>
<p>int omp_get_max_threads(void)


<p>omp_get_thread_num()
<p>Returns the thread number of the thread, within the team, making this call. This number will be between 0 and OMP_GET_NUM_THREADS-1. The master thread of the team is thread 0
<p>Format(C/C++):
<p>#include <omp.h>
<p>int omp_get_thread_num(void)


<p>omp_get_num_procs()
<p>Returns the number of processors that are available to the program.
<p>Format(C/C++):
<p>#include <omp.h>
<p>int omp_get_num_procs(void)


<p>omp_in_parallel()
<p>May be called to determine if the section of code which is executing is parallel or not.
<p>Format(C/C++):
<p>#include <omp.h>
<p>int omp_in_parallel(void)

<p>(https://computing.llnl.gov/tutorials/openMP/#Introduction)



			</center></p>

			
			<p><a href = "https://moodle.stmartin.edu/">Link to Course Moodle Page</a>


   </body>
</html>